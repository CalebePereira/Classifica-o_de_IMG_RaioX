# -*- coding: utf-8 -*-
"""Class_Raio_x.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1wyTe-F6l9D70kfL_loXcqLD8X0gIM70F

# **Montar o drive**

**As imagens estão salvas no google drive**
"""

from google.colab import drive
drive.mount('/content/drive')

import tensorflow as tf
from tensorflow.keras import layers

"""# **Abrindo o dataset**"""

# Separação do dataset em treino e validação

import tensorflow as tf
from tensorflow.keras import layers

path_dataset = '/content/drive/MyDrive/Raio-X-Classificação/train'
path_dataset2 = '/content/drive/MyDrive/Raio-X-Classificação/val'
IMG_SIZE = 128
batch_size = 32
NUM_CLASSES = 2

train_ds = tf.keras.preprocessing.image_dataset_from_directory(
    path_dataset,
    validation_split=0.2,
    subset="training",
    seed=1337,
    image_size=(IMG_SIZE, IMG_SIZE),
    batch_size=batch_size
)

val_ds = tf.keras.preprocessing.image_dataset_from_directory(
    path_dataset,
    validation_split=0.1,
    subset="validation",
    seed=1337,
    image_size=(IMG_SIZE, IMG_SIZE),
    batch_size=batch_size
)

"""# **Apresentando alguns exemplos**"""

# imprimir exemplos de imagens do dataset

import matplotlib.pyplot as plt

class_names = train_ds.class_names

plt.figure(figsize=(10, 10))
for images, labels in train_ds.take(1):
    for i in range(9):
        ax = plt.subplot(3, 3, i + 1)
        plt.imshow(images[i].numpy().astype("uint8"))
        plt.title(class_names[int(labels[i])])
        plt.axis("off")

"""# **Aumento de dados**"""

# Parte de melhoria de dados, imprimindo exemplos

data_augmentation = tf.keras.Sequential(
    [
        layers.experimental.preprocessing.RandomFlip("horizontal"),
        layers.experimental.preprocessing.RandomFlip("vertical"),
        layers.experimental.preprocessing.RandomRotation(0.3),
        layers.experimental.preprocessing.RandomContrast(0.4),
    ]
)
plt.figure(figsize=(10, 10))
for images, _ in train_ds.take(1):
    for i in range(9):
        augmented_images = data_augmentation(images)
        ax = plt.subplot(3, 3, i + 1)
        plt.imshow(augmented_images[0].numpy().astype("uint8"))
        plt.axis("off")

"""# **Transfer Learning**"""

# Model

from tensorflow.keras.layers.experimental import preprocessing
from tensorflow.keras.applications import EfficientNetB0, EfficientNetB7, ResNet50V2, ResNet101V2, ResNet152V2, VGG16, VGG19, InceptionResNetV2

def build_model(num_classes):
    inputs = layers.Input(shape=(IMG_SIZE, IMG_SIZE, 3))
    x = data_augmentation(inputs)
    model = VGG16(include_top=False, input_tensor=inputs, weights="imagenet")

    # Freeze the pretrained weights
    model.trainable = False

    # Rebuild top
    x = layers.GlobalAveragePooling2D(name="avg_pool")(model.output)
    x = layers.BatchNormalization()(x)

    top_dropout_rate = 0.46
    x = layers.Dropout(top_dropout_rate, name="top_dropout")(x)
    outputs = layers.Dense(num_classes, activation="softmax", name="pred")(x)

    # Compile
    model = tf.keras.Model(inputs, outputs, name="VGG16")
    optimizer = tf.keras.optimizers.SGD(learning_rate=5e-4)
    model.compile(optimizer=optimizer, loss="categorical_crossentropy", metrics=["accuracy"])
    return model

def unfreeze_model(model):
    for layer in model.layers:
        if not isinstance(layer, layers.BatchNormalization):
            layer.trainable = True

    optimizer = tf.keras.optimizers.SGD(learning_rate=5e-4)
    model.compile(optimizer=optimizer, loss="sparse_categorical_crossentropy", metrics=["accuracy"])
    return model

"""# **Iniciando os modelos e o treinamento**"""

# Ininicar Treinamento

model = build_model(num_classes=NUM_CLASSES)
model = unfreeze_model(model)

model.summary()

epochs = 20
hist = model.fit(train_ds, epochs=epochs, validation_data=val_ds, verbose=2, shuffle = True)

"""# **Mostrando gráficos de treinamento e salvando o modelo**"""

# Imprimir gráficos e salvar o resultado

import matplotlib.pyplot as plt
import pickle
import os

def plot_hist(hist):
    plt.plot(hist["accuracy"])
    plt.plot(hist["val_accuracy"])
    plt.title("model accuracy")
    plt.ylabel("accuracy")
    plt.xlabel("epoch")
    plt.legend(["train", "validation"], loc="upper left")
    plt.show()

def plot_loss(hist):
    plt.plot(hist["loss"])
    plt.plot(hist["val_loss"])
    plt.title("model Loss")
    plt.ylabel("loss")
    plt.xlabel("epoch")
    plt.legend(["train", "validation"], loc="upper left")
    plt.show()

model.save(os.path.join(path_dataset, 'Model_VGG16.h5'))
pickle.dump(hist.history, open(os.path.join(path_dataset, "history_VGG16.pkl"), "wb"))
plot_hist(hist.history)
plot_loss(hist.history)

"""# **Classificando uma imagem**"""

# Utilizar o resultado para testes singulares

from PIL import Image
import numpy as np
from tensorflow.keras.models import load_model
import os
import matplotlib.pyplot as plt
import cv2

model = load_model(os.path.join(path_dataset, 'Model_VGG19.h5'))

path_image = os.path.join(path_dataset, 'NORMAL/IM-0115-0001.jpeg')

img_array = cv2.imread(path_image)
img_array = cv2.cvtColor(img_array ,cv2.COLOR_BGR2RGB)
img = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))
img = img.reshape(-1, IMG_SIZE, IMG_SIZE, 3)

"""img = Image.open(path_image).resize((IMG_SIZE,IMG_SIZE))
img = np.array(img).astype(np.float)
#img = np.expand_dims(img, axis=-1)
img = img.reshape(-1, IMG_SIZE, IMG_SIZE, 3)
"""
print(img.shape[0])
print(img.shape[1])
print(img.shape[2])
print(img.shape[3])


probs = model.predict(img)
c = np.argmax(probs)
print(probs)
print(c)
print(class_names[c])

plt.imshow(img[0].astype("uint8"))
plt.title(class_names[c])
plt.axis("off")

"""# **Gerando as estatísticas**

Realizar os testes do modelo, passando a pasta de imagens de teste.
"""

# Utilizar o resultado para extrair dados

from sklearn.metrics import recall_score, precision_score, f1_score, confusion_matrix, accuracy_score
from PIL import Image
import numpy as np
from tensorflow.keras.models import load_model
import os
import matplotlib.pyplot as plt
import time

path_teste = '/content/drive/MyDrive/Raio-X-Classificação/test'
print('Carregando modelo...')
model = load_model('/content/drive/MyDrive/Raio-X-Classificação/train/Model_VGG16.h5')

class_names = ['NORMAL', 'PNEUMONIA']
filenames = []
for c in class_names:
  filenames += [os.path.join(c, f) for f in os.listdir(os.path.join(path_teste, c)) if f.endswith('jpeg')]


print(filenames)
y_true = []
y_pred = []
errors = []
tempos = []

for i, filename in enumerate(filenames):
  path_image = os.path.join(path_teste, filename)
  #img = Image.open(path_image).resize((IMG_SIZE,IMG_SIZE))
  #img = np.array(img).astype(np.float) 
  #img = np.expand_dims(img, axis=0)
  img_array = cv2.imread(path_image)
  img_array = cv2.cvtColor(img_array ,cv2.COLOR_BGR2RGB)
  img = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))
  img = img.reshape(-1, IMG_SIZE, IMG_SIZE, 3)
  start_time = time.time()
  probs = model.predict(img)
  elapsed_time = time.time() - start_time
  tempos.append(elapsed_time)

  index0 = filename.find('NORMAL')
  #MODELO CLASSIFICACAO DE PNEUMONIA
  if index0 != -1:
    cl_gt = 0
  else:
    cl_gt = 1
    
  cl = np.argmax(probs)
  y_pred.append(cl)
  y_true.append(cl_gt)
  if cl != cl_gt:
    errors.append(filename)
  print('(%d de %d) %s - pred: %d, gt: %d' % (i, len(filenames), filename, cl, cl_gt))

#print(errors)   #salva imagens que o modelo errou nesse vetor
print(accuracy_score(y_true, y_pred))
#print(recall_score(y_true, y_pred,  average='weighted', labels=np.unique(y_pred)))
print(precision_score(y_true, y_pred,  average='weighted', labels=np.unique(y_pred)))
#print(f1_score(y_true, y_pred,  average='weighted', labels=np.unique(y_pred)))
#print(confusion_matrix(y_true, y_pred))
#print(np.mean(tempos))
#print(np.std(tempos))

"""#Segundo Teste"""

# Utilizar o resultado para extrair dados

from sklearn.metrics import recall_score, precision_score, f1_score, confusion_matrix, accuracy_score
from PIL import Image
import numpy as np
from tensorflow.keras.models import load_model
import os
import matplotlib.pyplot as plt
import time

path_teste = '/content/drive/MyDrive/Raio-X-Classificação/test'
print('Carregando modelo...')
model = load_model('/content/drive/MyDrive/Raio-X-Classificação/train/Model_vgg16.h5')

class_names = ['NORMAL', 'PNEUMONIA']
filenames = []
for c in class_names:
  filenames += [os.path.join(c, f) for f in os.listdir(os.path.join(path_teste, c)) if f.endswith('jpeg')]


print(filenames)
y_true = []
y_pred = []
errors = []
tempos = []

for i, filename in enumerate(filenames):
  path_image = os.path.join(path_teste, filename)
  img = Image.open(path_image).resize((IMG_SIZE,IMG_SIZE))
  img = np.array(img).astype(np.float)
  img = np.expand_dims(img, axis=0)
  start_time = time.time()
  probs = model.predict(img)
  elapsed_time = time.time() - start_time
  tempos.append(elapsed_time)

  index0 = filename.find('NORMAL')
  """index0 = filename.find('cachara')
  index1 = filename.find('curimbata')
  index2= filename.find('dourado')
  index3 = filename.find('pacu')
  index4 = filename.find('piau')
  index5 = filename.find('piraputanga')
"""
#MODELO CLASSIFICACAO DE PNEUMONIA
  if index0 != -1:
    cl_gt = 0
  else:
    cl_gt = 1

  #modelo com as classes seguindo id padrao
"""  if index0 != -1:
    cl_gt = 0
  elif (index1 != -1):
    cl_gt = 1
  elif index2 != -1:
    cl_gt = 2
  elif filename.find('pacu') != -1:
    cl_gt = 3
  elif filename.find('piau') != -1:
    cl_gt = 4
  elif filename.find('piraputanga') != -1:
    cl_gt = 5
"""
  #ordem das classes do grance
""" if index0 != -1:
    cl_gt = 0
  elif (index1 != -1):
    cl_gt = 1
  elif index2 != -1:
    cl_gt = 2
  elif filename.find('pacu') != -1:
    cl_gt = 4
  elif filename.find('piau') != -1:
    cl_gt = 5
  elif filename.find('piraputanga') != -1:
    cl_gt = 6
"""
  cl = np.argmax(probs)
  y_pred.append(cl)
  y_true.append(cl_gt)
  if cl != cl_gt:
    errors.append(filename)
  print('(%d de %d) %s - pred: %d, gt: %d' % (i, len(filenames), filename, cl, cl_gt))

#print(errors)   #salva imagens que o modelo errou nesse vetor
print(accuracy_score(y_true, y_pred))
#print(recall_score(y_true, y_pred,  average='weighted', labels=np.unique(y_pred)))
print(precision_score(y_true, y_pred,  average='weighted', labels=np.unique(y_pred)))
#print(f1_score(y_true, y_pred,  average='weighted', labels=np.unique(y_pred)))
#print(confusion_matrix(y_true, y_pred))
#print(np.mean(tempos))
#print(np.std(tempos))

import matplotlib.pyplot as plt

model = load_model('/content/gdrive/MyDrive/Faculdade/imagens/Model_vgg16.h5')
model.summary()

layer = 5

inputs = model.inputs
outputs = model.layers[layer].output

model_activation = tf.keras.Model(inputs=inputs, outputs=outputs)

path_image = os.path.join(path_dataset, 'cachara/3105.JPG')
img = Image.open(path_image).resize((IMG_SIZE,IMG_SIZE))
img = np.array(img).astype(np.float)
img = np.expand_dims(img, axis=0)

activation_map = model_activation.predict(img)

print(activation_map.shape)
plt.figure(figsize=(10, 10))

ax = plt.subplot(3, 3, 1)
plt.imshow(img[0].astype(int))
plt.axis("off")

for f in range(8):
    ax = plt.subplot(3, 3, f + 2)
    plt.imshow(activation_map[0,:,:,f*3])
    plt.axis("off")